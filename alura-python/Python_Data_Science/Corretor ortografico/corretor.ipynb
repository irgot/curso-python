{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('igor': conda)",
   "display_name": "Python 3.8.5 64-bit ('igor': conda)",
   "metadata": {
    "interpreter": {
     "hash": "74dd7ce5e4bc88c43ed167e212bbe00dd3bf7501d2089049af961afbe56136a4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artigos.txt','r',encoding='utf8') as f:\n",
    "    artigos = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "416903"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "tokens = artigos.split()\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\igors\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "515907"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "len(lista_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(tokens):\n",
    "    lista_palavras = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "403106"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "len(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['imagem', 'Temos', 'a', 'seguinte', 'classe']\n"
    }
   ],
   "source": [
    "print(lista_palavras[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada=[]\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_normalizada=normalizacao(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['imagem', 'temos', 'a', 'seguinte', 'classe']\n"
    }
   ],
   "source": [
    "print(lista_normalizada[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "18465"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "len(set(lista_normalizada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'lógica'"
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "palavra_exemplo='lóigica'\n",
    "vocabulario = set(lista_normalizada)\n",
    "\n",
    "def invertendo_caracteres(fatias):\n",
    "    novas_palavras=[]\n",
    "    for E,D in fatias:\n",
    "        if len(D)>=2:\n",
    "            novas_palavras.append(E+D[1]+D[0]+D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "def trocando_caracteres(fatias):\n",
    "    novas_palavras=[]\n",
    "    letras='abcdefghijklmnopqrstuvwxyzáâàãéêèíîìóôòõúûùç'\n",
    "    for E,D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E+letra+D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras=[]\n",
    "    for E,D in fatias:\n",
    "        novas_palavras.append(E+D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    palavras_geradas=[]\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "            \n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas +=deletando_caracteres(fatias)\n",
    "    palavras_geradas +=trocando_caracteres(fatias)\n",
    "    palavras_geradas += invertendo_caracteres(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras+=gerador_palavras(palavra)        \n",
    "    return novas_palavras\n",
    "\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras=[]\n",
    "    letras='abcdefghijklmnopqrstuvwxyzáâàãéêèíîìóôòõúûùç'\n",
    "    for E,D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)    \n",
    "    return novas_palavras\n",
    "\n",
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta=max(palavras_geradas,key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "\n",
    "def novo_corretor(palavra):\n",
    "    candidatos=[]\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_geradas_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras=set(palavras_geradas+palavras_geradas_turbinado)    \n",
    "    candidatos = [palavra]\n",
    "    \n",
    "    for nova_palavra in todas_palavras:\n",
    "        if nova_palavra in vocabulario:\n",
    "            candidatos.append(nova_palavra)\n",
    "    # print('lógica' in vocabulario)\n",
    "    # print((candidatos))\n",
    "    palavra_correta=max(candidatos,key=probabilidade)\n",
    "    return palavra_correta\n",
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "frequencia.most_common(10)\n",
    "total_palavras = len(lista_normalizada)\n",
    "# frequencia['lógica']\n",
    "def probabilidade(palavra_gerada):\n",
    "    global frequencia\n",
    "    global total_palavras\n",
    "    return frequencia[palavra_gerada] / total_palavras\n",
    "\n",
    "# palavras_geradas = gerador_turbinado(gerador_palavras(palavra_exemplo))\n",
    "\n",
    "novo_corretor(palavra_exemplo)\n",
    "\n",
    "# vocabulario\n",
    "# print(palavras_geradas)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo,'r',encoding='utf8')\n",
    "    for linha in f:\n",
    "        correta,errada = linha.split()\n",
    "        lista_palavras_teste.append((correta,errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "lista_teste = cria_dados_teste('palavras.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador(testes,vocabulario):\n",
    "    numero_palavras=len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida=0\n",
    "    for correta,errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        desconhecida+=(correta not in vocabulario)\n",
    "        if(palavra_corrigida==correta):\n",
    "            acertou+=1\n",
    "        \n",
    "            \n",
    "    taxa_acerto = round(acertou * 100 / numero_palavras,2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras,2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras\")\n",
    "    print(f\"A taxa de plavras desconhecidas é {taxa_desconhecida}% de {numero_palavras} palavras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "76.34% de 186 palavras\nA taxa de plavras desconhecidas é 6.99% de 186 palavras\n"
    }
   ],
   "source": [
    "\n",
    "avaliador(lista_teste,vocabulario)\n",
    "#39.25% de 186 palavras\n",
    "#41.4% de 186 palavras\n",
    "#76.34% de 186 palavras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}